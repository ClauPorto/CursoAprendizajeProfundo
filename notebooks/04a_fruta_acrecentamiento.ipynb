{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04a_fruta_acrecentamiento.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/04a_fruta_acrecentamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkjE8iVcbTFB",
        "colab_type": "text"
      },
      "source": [
        "# Acrecentamieto de datos para el reconocimiento de frutas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e2CgsEhowVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.layers import Add, ZeroPadding2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFU23l2L1dzZ",
        "colab_type": "text"
      },
      "source": [
        "## Conjunto de datos\n",
        "\n",
        "Vamos a entrenar una red neuronal  convolucional para reconocimiento de frutas usando el conjunto de datos: *Fruits 360*, el cual está compuesto por imágenes a color de $100 \\times 100 \\times 3$ de 75 frutas distintas. \n",
        "\n",
        "Para descargar este conjunto de imágenes simplemente clonamos el repositorio:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ere1HB9TjUV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Horea94/Fruit-Images-Dataset.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suazw3VBoB7N",
        "colab_type": "text"
      },
      "source": [
        "La estructura del repositorio clonado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3_lXAIBoBm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls Fruit-Images-Dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-KCot1srUX-",
        "colab_type": "text"
      },
      "source": [
        "El conjunto de imágenes se encuentra dividido en subconjuntos de entrenamiento y prueba, los cuales están contenidos en los subdirectorios `Training` y `Test`. A su vez, estos subdirectorios contienen un directorio por cada categoría de fruta y dentro de cada uno de ellos están las imágenes correspondientes. Vamos a recopilar cada una de estas imágenes con su correspondiente etiqueta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdo4LjLgl3kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Conjunto de entrenamiento\n",
        "ruta_ent = 'Fruit-Images-Dataset/Training'\n",
        "ruta_prueba = 'Fruit-Images-Dataset/Test'\n",
        "dirs_ent = os.listdir(ruta_ent)\n",
        "dirs_prueba = os.listdir(ruta_prueba)\n",
        "\n",
        "etiquetas = dirs_ent\n",
        "ind_a_str = {i:s for i,s in enumerate(dirs_ent)}\n",
        "str_a_ind = {s:i for i,s in enumerate(dirs_ent)}\n",
        "\n",
        "img_ent = []\n",
        "etiq_ent = []\n",
        "cat_ent = []\n",
        "for e in etiquetas:\n",
        "  for f in os.listdir(ruta_ent + '/' + e):\n",
        "    img_ent.append(ruta_ent + '/' + e + '/' + f)\n",
        "    etiq_ent.append(e)\n",
        "    cat_ent.append(str_a_ind[e])\n",
        "\n",
        "# Conjunto de prueba\n",
        "ruta_prueba = 'Fruit-Images-Dataset/Test'\n",
        "dirs_prueba = os.listdir(ruta_prueba)\n",
        "\n",
        "img_prueba = []\n",
        "etiq_prueba = []\n",
        "cat_prueba = []\n",
        "for e in etiquetas:\n",
        "  for f in os.listdir(ruta_prueba + '/' + e):\n",
        "    img_prueba.append(ruta_prueba + '/' + e + '/' + f)\n",
        "    etiq_prueba.append(e)\n",
        "    cat_prueba.append(str_a_ind[e])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhP8cTkHor9c",
        "colab_type": "text"
      },
      "source": [
        "Ahora inspeccionémos el número de imágenes de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-Kc-Xhofg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_ej = len(img_ent)\n",
        "print(n_ej)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbeH0li46MCX",
        "colab_type": "text"
      },
      "source": [
        "Ahora veámos cuántas clases tenemos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BebSFOjq6PqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clases = len(dirs_ent)\n",
        "print(n_clases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNRYJ-1L3hoH",
        "colab_type": "text"
      },
      "source": [
        "Ya descargadas las imágenes, podemos visualizar algunas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBmgQ7cR321G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand_s = np.random.randint(n_ej, size = 9)\n",
        "for i in range(9):\n",
        "  img = plt.imread(img_ent[rand_s[i]])\n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4rNR17H7mvO",
        "colab_type": "text"
      },
      "source": [
        "Algunos ejemplos de rutas y sus correspondientes etiquetas e idenficadores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohH3Xp70wb9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(list(zip(img_ent, etiq_ent, cat_ent)), columns =['Archivo', 'Etiqueta', u'Categoría'])\n",
        "df.sample(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUZA8xLql5jR",
        "colab_type": "text"
      },
      "source": [
        "Hacemos los mismo para imágenes del conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsIrAB_Wl_iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_prueba = pd.DataFrame(list(zip(img_prueba, etiq_prueba, cat_prueba)), columns =['Archivo', 'Etiqueta', u'Categoría'])\n",
        "df.sample(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89JrHdun1ZJv",
        "colab_type": "text"
      },
      "source": [
        "## Partición del conjunto de entrenamiento\n",
        "Ahora vamos a dividir el conjunto de entrenamiento disponible en entrenamiento y validación para monitorear métricas y pérdidas en estos 2 subconjunto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJfDs9um1qj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_ent = int(np.floor(df.shape[0] * 0.8))\n",
        "perm = np.random.permutation(df.shape[0])\n",
        "df_ent = df.iloc[perm[:n_ent]]\n",
        "df_val = df.iloc[perm[n_ent:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxklYNIvy8SV",
        "colab_type": "text"
      },
      "source": [
        "## Lectura y preprocesamiento de imágenes\n",
        "Generamos funciones para leer y preprocesar nuestras imágenes de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PFvbetFzM6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from timeit import default_timer as timer\n",
        "\n",
        "class ImGen:\n",
        "  def __init__(self):\n",
        "    self.gen_ent = ImageDataGenerator(rescale=1./255,\n",
        "                                      rotation_range=90,\n",
        "                                      horizontal_flip=True)\n",
        "            \n",
        "  def __call__(self):\n",
        "    return self.gen_ent.flow_from_dataframe(dataframe=df_ent, \n",
        "                                            directory=\"./\", \n",
        "                                            x_col=u'Archivo', \n",
        "                                            y_col=u'Etiqueta',\n",
        "                                            target_size=(64,64),\n",
        "                                            batch_size=64, \n",
        "                                            class_mode=\"sparse\")\n",
        "    \n",
        "ent_ds = tf.data.Dataset.from_generator(ImGen(),  \n",
        "                                        output_types=(tf.float32, tf.float32))\n",
        "\n",
        "start = timer()\n",
        "for i, (x, y_true) in enumerate(ent_ds, start=1):\n",
        "    plt.subplot(2, 5, i)\n",
        "    plt.imshow(x[0])\n",
        "    plt.axis('off')\n",
        "    if i == 10:\n",
        "        break\n",
        "\n",
        "end = timer()\n",
        "print(end - start) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RGCmVy1c3Rw",
        "colab_type": "text"
      },
      "source": [
        "De forma alternativa, podemos usar la función de mapeo del API de datos de Tensorflow: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjLJkFGVW7yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def procesa_imagen(ruta, categoria, imsize=(64,64)):\n",
        "    imagen = tf.io.read_file(ruta)\n",
        "    imagen = tf.image.decode_jpeg(imagen, channels=3)\n",
        "    imagen = tf.image.resize(imagen, imsize)\n",
        "    imagen /= 255.0\n",
        "    \n",
        "    imagen = tf.image.random_flip_left_right(imagen)\n",
        "    imagen = tf.image.random_flip_up_down(imagen)\n",
        "    imagen = tf.image.random_crop(imagen, size=[64, 64, 3])\n",
        "    imagen = tf.image.rot90(imagen, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    imagen = tf.clip_by_value(imagen, 0, 1)\n",
        "    \n",
        "    return imagen, categoria\n",
        "\n",
        "ent_ds = tf.data.Dataset.from_tensor_slices((df_ent['Archivo'], df_ent['Categoría']))\n",
        "ent_ds = ent_ds.shuffle(n_ej)\n",
        "ent_ds = ent_ds.map(procesa_imagen, num_parallel_calls=8)\n",
        "ent_ds = ent_ds.batch(64)\n",
        "ent_ds = ent_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "start = timer()\n",
        "for i, (x, y_true) in enumerate(ent_ds, start=1):\n",
        "    plt.subplot(2, 5, i)\n",
        "    plt.imshow(x[0])\n",
        "    plt.axis('off')\n",
        "    if i == 10:\n",
        "        break\n",
        "end = timer()\n",
        "print(end - start) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpklupPo7mrT",
        "colab_type": "text"
      },
      "source": [
        "Otra estrategia es serializar los ejemplos y guardarlos como [TFRecords](https://www.tensorflow.org/tutorials/load_data/tfrecord):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL0BXW00f5Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def valor_byte(valor):\n",
        "  if isinstance(valor, type(tf.constant(0))):\n",
        "    valor = valor.numpy() \n",
        "  \n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[valor]))\n",
        "\n",
        "def valor_int64(valor):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[valor]))\n",
        "\n",
        "def ejemplo_imagen(ruta, etiqueta):\n",
        "  imagen = tf.io.read_file(ruta)\n",
        "  imagen = tf.image.decode_jpeg(imagen)\n",
        "  imagen = tf.image.resize(imagen, (64,64))\n",
        "  imagen /= 255.0\n",
        "  cadena_img = tf.io.serialize_tensor(imagen)\n",
        "  tam_img = imagen.shape\n",
        "\n",
        "  caract = {\n",
        "        'height': valor_int64(tam_img[0]),\n",
        "        'width': valor_int64(tam_img[1]),\n",
        "        'depth': valor_int64(tam_img[2]),\n",
        "        'label': valor_int64(etiqueta),\n",
        "        'image_raw': valor_byte(cadena_img),\n",
        "      }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=caract))\n",
        "\n",
        "tfr_ent = 'ent_images.tfrecords'\n",
        "with tf.io.TFRecordWriter(tfr_ent) as writer:\n",
        "  for ruta,etiqueta in zip(df_ent['Archivo'], df_ent['Categoría']):\n",
        "    tf_ej = ejemplo_imagen(ruta, etiqueta)\n",
        "    writer.write(tf_ej.SerializeToString())\n",
        "\n",
        "tfr_val = 'val_images.tfrecords'\n",
        "with tf.io.TFRecordWriter(tfr_val) as writer:\n",
        "  for ruta,etiqueta in zip(df_val['Archivo'], df_val['Categoría']):\n",
        "    tf_ej = ejemplo_imagen(ruta, etiqueta)\n",
        "    writer.write(tf_ej.SerializeToString())\n",
        "\n",
        "tfr_prueba = 'prueba_images.tfrecords'\n",
        "with tf.io.TFRecordWriter(tfr_prueba) as writer:\n",
        "  for ruta,etiqueta in zip(df_prueba['Archivo'], df_prueba['Categoría']):\n",
        "    tf_ej = ejemplo_imagen(ruta, etiqueta)\n",
        "    writer.write(tf_ej.SerializeToString())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F27DrdhA6jVM",
        "colab_type": "text"
      },
      "source": [
        "Posteriormente, podemos leerlos como un `tf.data.Dataset` usando `tf.data.TFRecordDataset`. Para ello es necesario definir una función para deserializar cada ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_3Fw0zjeSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imagen_tfr(ej_proto):\n",
        "  caract = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  ej = tf.io.parse_single_example(ej_proto, caract)\n",
        "  imagen = tf.io.parse_tensor(ej['image_raw'], out_type = float)\n",
        "  img_shape = [ej['height'], ej['width'], ej['depth']]\n",
        "  imagen = tf.reshape(imagen, img_shape)\n",
        "\n",
        "  imagen = tf.image.random_flip_left_right(imagen)\n",
        "  imagen = tf.image.random_flip_up_down(imagen)\n",
        "  imagen = tf.image.random_crop(imagen, size=[64, 64, 3])\n",
        "  imagen = tf.image.rot90(imagen, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "  imagen = tf.clip_by_value(imagen, 0, 1)\n",
        "\n",
        "  return imagen, ej['label']\n",
        "\n",
        "ent_ds = tf.data.TFRecordDataset('ent_images.tfrecords', buffer_size = 100, num_parallel_reads=8)\n",
        "ent_ds = ent_ds.shuffle(n_ej)\n",
        "ent_ds = ent_ds.map(imagen_tfr)\n",
        "ent_ds = ent_ds.batch(64)\n",
        "ent_ds = ent_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "start = timer()\n",
        "for i, (x, y_true) in enumerate(ent_ds, start=1):\n",
        "    plt.subplot(2, 5, i)\n",
        "    plt.imshow(x[0])\n",
        "    plt.axis('off')\n",
        "    if i == 10:\n",
        "        break\n",
        "\n",
        "end = timer()\n",
        "print(end - start) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgnwuBq1Ow0p",
        "colab_type": "text"
      },
      "source": [
        "Asimismo, definimos la función para cargar las imágenes de validación: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac9WZKBKlEBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def carga_una_imagen(ej_proto):\n",
        "  caract = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  ej = tf.io.parse_single_example(ej_proto, caract)\n",
        "  imagen = tf.io.parse_tensor(ej['image_raw'], out_type = float)\n",
        "  img_shape = [ej['height'], ej['width'], ej['depth']]\n",
        "  imagen = tf.reshape(imagen, img_shape)\n",
        "\n",
        "  return imagen, ej['label']\n",
        "  \n",
        "val_ds = tf.data.TFRecordDataset('val_images.tfrecords', buffer_size = 100, num_parallel_reads=8)\n",
        "val_ds = val_ds.map(carga_una_imagen)\n",
        "val_ds = val_ds.batch(1)\n",
        "\n",
        "prueba_ds = tf.data.TFRecordDataset('val_images.tfrecords', buffer_size = 100, num_parallel_reads=8)\n",
        "prueba_ds = prueba_ds.map(carga_una_imagen)\n",
        "prueba_ds = prueba_ds.batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxlpp8mOcpV_",
        "colab_type": "text"
      },
      "source": [
        "## Definición de la red\n",
        "Ahora vamos a definir una red neuronal convolucional simple con bloques de tipo residual: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhjFJjmpYDkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.zp01 = ZeroPadding2D((3, 3))\n",
        "    self.conv01 = Conv2D(64, (7, 7), strides=(2, 2))\n",
        "    self.bn01 = BatchNormalization(axis = 3)\n",
        "    self.act01 = Activation('relu')\n",
        "    self.pool01 = MaxPooling2D((3, 3), strides=(2, 2))\n",
        "\n",
        "    self.conv11 = Conv2D(64, kernel_size = (1, 1), strides = (1,1))\n",
        "    self.bn11 = BatchNormalization(axis = 3)\n",
        "    self.act11 = Activation('relu')\n",
        "    self.conv12 = Conv2D(64, kernel_size = (3, 3), strides = (1,1), padding = 'same')\n",
        "    self.bn12 = BatchNormalization(axis = 3)\n",
        "    self.act12 = Activation('relu')\n",
        "    self.conv13 = Conv2D(256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')\n",
        "    self.bn13 = BatchNormalization(axis = 3)\n",
        "    self.conv14 = Conv2D(256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')\n",
        "    self.bn14 = BatchNormalization(axis = 3)\n",
        "    self.add1 = Add()\n",
        "    self.act13 = Activation('relu')\n",
        "    \n",
        "\n",
        "    self.conv21 = Conv2D(64, kernel_size = (1, 1), strides = (1,1), padding = 'valid')\n",
        "    self.bn21 = BatchNormalization(axis = 3)\n",
        "    self.act21 = Activation('relu')\n",
        "    self.conv22 = Conv2D(64, kernel_size = (3, 3), strides = (1,1), padding = 'same')\n",
        "    self.bn22 = BatchNormalization(axis = 3)\n",
        "    self.act22 = Activation('relu')\n",
        "    self.conv23 = Conv2D(256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')\n",
        "    self.bn23 = BatchNormalization(axis = 3)\n",
        "    self.add2 = Add()\n",
        "    self.act23 = Activation('relu')\n",
        "    \n",
        "    self.conv31 = Conv2D(64, kernel_size = (1, 1), strides = (1,1), padding = 'valid')\n",
        "    self.bn31 = BatchNormalization(axis = 3)\n",
        "    self.act31 = Activation('relu')\n",
        "    self.conv32 = Conv2D(64, kernel_size = (3, 3), strides = (1,1), padding = 'same')\n",
        "    self.bn32 = BatchNormalization(axis = 3)\n",
        "    self.act32 = Activation('relu')\n",
        "    self.conv33 = Conv2D(256, kernel_size = (1, 1), strides = (1,1), padding = 'valid')\n",
        "    self.bn33 = BatchNormalization(axis = 3)\n",
        "    self.add3 = Add()\n",
        "    self.act33 = Activation('relu')\n",
        "    \n",
        "    self.ap = AveragePooling2D((2,2))\n",
        "    self.flat = Flatten()\n",
        "    \n",
        "    self.dense = Dense(512, activation='relu', kernel_regularizer='l2', \n",
        "                       bias_regularizer='l2')\n",
        "    self.dp = Dropout(0.7)\n",
        "    self.sm = Dense(n_clases, activation='softmax', kernel_regularizer='l2', \n",
        "                    bias_regularizer='l2')\n",
        "\n",
        "  def call(self, x): \n",
        "    # etapa 1\n",
        "    x \n",
        "    x = self.zp01(x)\n",
        "    x = self.conv01(x)\n",
        "    x = self.bn01(x)\n",
        "    x = self.act01(x)\n",
        "    x = self.pool01(x)\n",
        "    \n",
        "    # etapa 2: bloque convolucional\n",
        "    x_s = x     \n",
        "    x = self.conv11(x)\n",
        "    x = self.bn11(x)\n",
        "    x = self.act11(x)\n",
        "    x = self.conv12(x)\n",
        "    x = self.bn12(x)\n",
        "    x = self.act12(x)\n",
        "    x = self.conv13(x)\n",
        "    x = self.bn13(x)\n",
        "    x_s = self.conv14(x_s)\n",
        "    x_s = self.bn14(x_s)\n",
        "    x = self.add1([x, x_s])\n",
        "    x = self.act13(x)\n",
        "\n",
        "    # etapa 3: primer bloque identidad\n",
        "    x_s = x     \n",
        "    x = self.conv21(x)\n",
        "    x = self.bn21(x)\n",
        "    x = self.act21(x)\n",
        "    x = self.conv22(x)\n",
        "    x = self.bn22(x)\n",
        "    x = self.act22(x)\n",
        "    x = self.conv23(x)\n",
        "    x = self.bn23(x)\n",
        "    x = self.add2([x, x_s])\n",
        "    x = self.act23(x)\n",
        "    \n",
        "    # etapa 4: segundo bloque identidad\n",
        "    x_s = x     \n",
        "    x = self.conv31(x)\n",
        "    x = self.bn31(x)\n",
        "    x = self.act31(x)\n",
        "    x = self.conv32(x)\n",
        "    x = self.bn32(x)\n",
        "    x = self.act32(x)\n",
        "    x = self.conv33(x)\n",
        "    x = self.bn33(x)\n",
        "    x = self.add3([x, x_s])\n",
        "    x = self.act33(x)\n",
        "  \n",
        "    # etapa 5: bloque de clasificación\n",
        "    x = self.ap(x)\n",
        "    x = self.flat(x)\n",
        "    x = self.dense(x)\n",
        "    x = self.dp(x)\n",
        "    x = self.sm(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVycJBI3PkH9",
        "colab_type": "text"
      },
      "source": [
        "Construimos nuestra red y visualizamos sus características:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzgH0TcsYLbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = CNN()\n",
        "modelo.build(input_shape=(None, 64, 64 , 3))\n",
        "modelo.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7y9ZRAU84XW",
        "colab_type": "text"
      },
      "source": [
        "Ahora definimos las funciones para realizar la propagación hacia adelante y la retropropagación en los ejemplos de entrenamiento y la propagación hacia adelante para los ejemplos de validación y de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LgAl9z-1Rdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def paso_ent(x, y, modelo, fn_perdida, optimizador):\n",
        "    with tf.GradientTape() as cinta:\n",
        "        y_pred = modelo(x)\n",
        "        perdida = fn_perdida(y, y_pred)\n",
        "    gradientes = cinta.gradient(perdida, modelo.trainable_variables)\n",
        "    optimizador.apply_gradients(zip(gradientes, modelo.trainable_variables))\n",
        "    return y_pred\n",
        "  \n",
        "@tf.function\n",
        "def paso_prueba(imagen, modelo):\n",
        "  return modelo(imagen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bDDPKJFmCYSF"
      },
      "source": [
        "## Entrenamiento\n",
        "Con las funciones definidas anteriormente entrenamos nuestra red optimizando la función de entropía cruzada categórica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3R1eNIoeVWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "fn_perdida = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizador = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "perdida_ent = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "exactitud_ent = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "perdida_val = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "exactitud_val = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "hist_perdida_ent = []\n",
        "hist_exactitud_ent = []\n",
        "\n",
        "hist_perdida_val = []\n",
        "hist_exactitud_val = []\n",
        "\n",
        "for epoca in range(5):\n",
        "    for paso, (x, y) in enumerate(ent_ds):\n",
        "        y_pred = paso_ent(x, y,  modelo, fn_perdida, optimizador)\n",
        "        perdida_ent(y, y_pred)\n",
        "        exactitud_ent(y, y_pred)\n",
        "        \n",
        "    for (x, y) in val_ds:\n",
        "        y_pred = paso_prueba(x, modelo)\n",
        "        perdida_val(y, y_pred)\n",
        "        exactitud_val(y, y_pred)\n",
        "    \n",
        "    perdida_ent_res = perdida_ent.result().numpy()\n",
        "    exactitud_ent_res = exactitud_ent.result().numpy() * 100\n",
        "    perdida_ent.reset_states()\n",
        "    exactitud_ent.reset_states()\n",
        "    hist_perdida_ent.append(perdida_ent_res)\n",
        "    hist_exactitud_ent.append(exactitud_ent_res)\n",
        "\n",
        "    perdida_val_res = perdida_val.result().numpy()\n",
        "    exactitud_val_res = exactitud_val.result().numpy() * 100\n",
        "    perdida_val.reset_states()\n",
        "    exactitud_val.reset_states()\n",
        "    hist_perdida_val.append(perdida_val_res)\n",
        "    hist_exactitud_val.append(exactitud_val_res)\n",
        "  \n",
        "    print('E{:2d} CCE(E)={:6.2f}, Exactidud(E)={:6.2f} CCE(V)={:6.2f} Exactitud(V)={:6.2f}'.format(epoca, \n",
        "                                                                                                   perdida_ent_res, \n",
        "                                                                                                   exactitud_ent_res,\n",
        "                                                                                                   perdida_val_res, \n",
        "                                                                                                   exactitud_val_res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rB05PJfW55Bh"
      },
      "source": [
        "Visualicemos la evolución de la pérdida de entropía cruzada y la exactitud durante el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23WTILcfSGlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(1)\n",
        "plt.plot(hist_perdida_ent, color='red', label='Entrenamiento')\n",
        "plt.plot(hist_perdida_val, color='blue', label=u'Validación')\n",
        "plt.xlabel(u'Época')\n",
        "plt.ylabel(u'Pérdida')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(hist_exactitud_ent, color='red', label='Entrenamiento')\n",
        "plt.plot(hist_exactitud_val, color='blue', label=u'Validación')\n",
        "plt.xlabel(u'Época')\n",
        "plt.ylabel(u'Exactitud')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuEsNw7DoKey",
        "colab_type": "text"
      },
      "source": [
        "Ya entrenado nuestro modelo, procedemos a evaluar su desempeño en el conjunto de imágenes de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHgbTjAfUvd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exactitud_prueba = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for i, (x, y) in enumerate(prueba_ds):\n",
        "  y_pred = paso_prueba(x, modelo)\n",
        "  exactitud_prueba(y, y_pred)\n",
        "\n",
        "exactitud_prueba = exactitud_prueba.result().numpy() * 100\n",
        "print(\"Exactitud en validación: {:02.2f}%\".format(exactitud_prueba))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhqhww4NW8go",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, visualizamos algunos ejemplos de predicciónes hechas por el modelo en el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RuXsa3VGlwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prueba_ds = prueba_ds.shuffle(len(img_prueba))\n",
        "\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "for i, (x, y) in enumerate(prueba_ds, start=1):\n",
        "    ax = fig.add_subplot(2, 5, i)\n",
        "    ax.imshow(x[0])\n",
        "    y_pred = np.argmax(modelo(x))\n",
        "    etiq = ind_a_str[y_pred]\n",
        "    ax.imshow(x[0])\n",
        "    ax.set_title(ind_a_str[y.numpy()[0]])\n",
        "    if etiq == ind_a_str[y.numpy()[0]]:\n",
        "      ax.text(1,8, etiq, color = 'b')\n",
        "    else:  \n",
        "      ax.text(1,8, etiq, color = 'r')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    if i == 10:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}