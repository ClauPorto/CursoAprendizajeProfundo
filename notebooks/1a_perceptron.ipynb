{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1a_perceptron.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/1a_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v8X1X5KGWhZT"
      },
      "source": [
        "# Neuronas artificiales \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C4qjFKtZafzQ",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ec2lh4iaj7J"
      },
      "source": [
        "La operación que lleva a cabo una neurona artificial, está dada por la suma pesada evaluada en una función de activación $\\phi$.  Una de las primeras funciones de activación utilizadas fue la escalón unitario, definida como\n",
        "\n",
        "$\n",
        "\\phi(x) = \\begin{cases} 1, & \\text{si } x > 0\\\\0, & \\text{en caso contrario}\\end{cases}\n",
        "$\n",
        "\n",
        "Esta se puede llevar a cabo con la siguiente función de Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DF3X4nFS8ze",
        "colab": {}
      },
      "source": [
        "def escalon(z):\n",
        "    if z > 0.0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tHUpzFQLY8Y1"
      },
      "source": [
        "Por su parte, la suma pesada simplemente consiste en multiplicar cada entrada por su correspondiente peso y sumarle el sesgo. Esto lo podemos expresar como\n",
        "\n",
        "$\n",
        "z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\cdots + w_d \\cdot x_d + b \n",
        "$\n",
        "\n",
        "En su forma vectorial\n",
        "\n",
        "$\n",
        "z = \\mathbf{w}^T \\mathbf{x} + b\n",
        "$\n",
        "\n",
        "Para realizar esto en Python, podemos usar la función `dot` de NumPY de la siguiente manera `z = np.dot(w.T, x) + b`. Así, la operación de la neurona completa sería:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G61wzAPaT3r3",
        "colab": {}
      },
      "source": [
        "def neurona(x, w, b):\n",
        "  z = np.dot(w.T, x) + b\n",
        "  a = escalon(z)\n",
        "\n",
        "  return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a-VjUcwrZpmW"
      },
      "source": [
        "Esta neurona es capaz de aproximar el operador OR, cuya salida es 1 cuando al menos 1 de las 2 entradas es 1:\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$\n",
        "| ------------- |:-------------:| -----:|\n",
        "|0 |0 |0|\n",
        "|0 |1 |1|\n",
        "|1 |0 |1|\n",
        "|1 |1 |1|\n",
        "\n",
        "La neurona recibe 2 valores binarios como entrada y produce un valor binario como salida. Específicamente, la neurona calcularía\n",
        "\n",
        "$\n",
        "\\hat{y} = \\phi(w_1 \\cdot x_1 + w_2 \\cdot x_2 + b)\n",
        "$\n",
        "\n",
        "Para poder aproximar la operación OR es necesario encontrar los valores apropiados de $w_1$, $w_2$ y $b$. Una posible elección sería 10, 10 y -5 respectivamente. Verifiquemos estos valores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XE5LjZh9TWcF",
        "outputId": "97bce82b-26aa-4e02-9c81-b4cece9c9138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "w = np.array([10, 10]).T\n",
        "b = -5\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "  y_hat = neurona(X[i, :], w, b)\n",
        "  print('x = {0}, y_hat = {1}'.format(X[i, :], y_hat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = [0. 0.], y_hat = 0.0\n",
            "x = [0. 1.], y_hat = 1.0\n",
            "x = [1. 0.], y_hat = 1.0\n",
            "x = [1. 1.], y_hat = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnqeydbxeavD"
      },
      "source": [
        "De forma similar, podemos aproximar la operación AND:\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$\n",
        "| ------------- |:-------------:| -----:|\n",
        "|0 |0 |0|\n",
        "|0 |1 |0|\n",
        "|1 |0 |0|\n",
        "|1 |1 |1|\n",
        "\n",
        "Nuevamente, debemos encontrar los valores apropiados para los pesos y el sesgo. Probemos con $w_1 = 10$, $w_2 = 10$ y $b = -15$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hdcp_-oqTc75",
        "outputId": "46b141a3-6a19-47aa-dba5-bbfa5b3ceedc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "w = np.array([10, 10]).T\n",
        "b = -15 \n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "  y_hat = neurona(X[i, :], w, b)\n",
        "  print('x = {0}, y_hat = {1}'.format(X[i, :], y_hat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = [0. 0.], y_hat = 0.0\n",
            "x = [0. 1.], y_hat = 0.0\n",
            "x = [1. 0.], y_hat = 0.0\n",
            "x = [1. 1.], y_hat = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJW4l3Gcx-j2",
        "colab_type": "text"
      },
      "source": [
        "También podemos aproximar la negación de la operación AND (NAND):\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$\n",
        "| ------------- |:-------------:| -----:|\n",
        "|0 |0 |1|\n",
        "|0 |1 |1|\n",
        "|1 |0 |1|\n",
        "|1 |1 |0|\n",
        "\n",
        "En este caso, los valores para los pesos y el sesgo son $w_1 = -10$, $w_2 = -10$ y $b = 15$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJoT4krVyGEo",
        "colab_type": "code",
        "outputId": "305aa652-144f-4924-969b-080bdebc6a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "w = np.array([-10, -10]).T\n",
        "b = 15 \n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "  y_hat = neurona(X[i, :], w, b)\n",
        "  print('x = {0}, y_hat = {1}'.format(X[i, :], y_hat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = [0. 0.], y_hat = 1.0\n",
            "x = [0. 1.], y_hat = 1.0\n",
            "x = [1. 0.], y_hat = 1.0\n",
            "x = [1. 1.], y_hat = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7kivF042Heh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptron(X, y, n_epochs = 10):\n",
        "    w_new = np.zeros(X.shape[1])\n",
        "    b_new = 0\n",
        "    for i in range(n_epochs):\n",
        "        serr = 0.0\n",
        "        for j in range(X.shape[0]):\n",
        "            w_old = w_new\n",
        "            b_old = b_new\n",
        "            \n",
        "            y_hat = neurona(X[j], w_old, b_old)\n",
        "            error = y[j] - y_hat\n",
        "           \n",
        "            w_new = w_old + error * X[j]     \n",
        "            b_new = b_old + error\n",
        "           \n",
        "            serr += np.abs(error)\n",
        "        print(\"Epoch {0}: error = {1}\".format(i, serr / float(X.shape[0])))\n",
        "\n",
        "    return w_new, b_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqukG0wL9DhC",
        "colab_type": "text"
      },
      "source": [
        "Probemos el algoritmo del perceptrón para aprender la operación lógica OR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOFZdaie9D6n",
        "colab_type": "code",
        "outputId": "9e2e37e9-ba7a-404d-df67-0b4dea2b289f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "y_or = np.array([0., 1., 1., 1.]) \n",
        "\n",
        "w, b = perceptron(X, y_or)\n",
        "\n",
        "print('\\nw_1 = {0}, w_2 = {1}, b = {2}'.format(w[0], w[1], b))\n",
        "print('x_1\\tx_2\\ty\\ty_hat')\n",
        "for i in range(X.shape[0]):\n",
        "  y_hat = neurona(X[i], w, b)\n",
        "  print('{0}\\t{1}\\t{2}\\t{3}'.format(X[i, 0], X[i, 1], y_or[i], y_hat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: error = 0.25\n",
            "Epoch 1: error = 0.5\n",
            "Epoch 2: error = 0.25\n",
            "Epoch 3: error = 0.0\n",
            "Epoch 4: error = 0.0\n",
            "Epoch 5: error = 0.0\n",
            "Epoch 6: error = 0.0\n",
            "Epoch 7: error = 0.0\n",
            "Epoch 8: error = 0.0\n",
            "Epoch 9: error = 0.0\n",
            "\n",
            "w_1 = 1.0, w_2 = 1.0, b = 0.0\n",
            "x_1\tx_2\ty\ty_hat\n",
            "0.0\t0.0\t0.0\t0.0\n",
            "0.0\t1.0\t1.0\t1.0\n",
            "1.0\t0.0\t1.0\t1.0\n",
            "1.0\t1.0\t1.0\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSinG4G6rSCF",
        "colab_type": "text"
      },
      "source": [
        "Ahora veamos qué ocurre si en lugar de la operación OR tratamos de aprender la operación AND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqyp83uorS_i",
        "colab_type": "code",
        "outputId": "10c5eed3-0883-4090-98d2-34232ce6ab76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "y_and = np.array([0., 0., 0., 1.])\n",
        "w, b = perceptron(X, y_and)\n",
        "\n",
        "print('\\nw_1 = {0}, w_2 = {1}, b = {2}'.format(w[0], w[1], b))\n",
        "print('x_1\\tx_2\\ty\\ty_hat')\n",
        "for i in range(X.shape[0]):\n",
        "  y_hat = neurona(X[i], w, b)\n",
        "  print('{0}\\t{1}\\t{2}\\t{3}'.format(X[i, 0], X[i, 1], y_and[i], y_hat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: error = 0.25\n",
            "Epoch 1: error = 0.75\n",
            "Epoch 2: error = 0.75\n",
            "Epoch 3: error = 0.5\n",
            "Epoch 4: error = 0.25\n",
            "Epoch 5: error = 0.0\n",
            "Epoch 6: error = 0.0\n",
            "Epoch 7: error = 0.0\n",
            "Epoch 8: error = 0.0\n",
            "Epoch 9: error = 0.0\n",
            "\n",
            "w_1 = 2.0, w_2 = 1.0, b = -2.0\n",
            "x_1\tx_2\ty\ty_hat\n",
            "0.0\t0.0\t0.0\t0.0\n",
            "0.0\t1.0\t0.0\t0.0\n",
            "1.0\t0.0\t0.0\t0.0\n",
            "1.0\t1.0\t1.0\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c406Vb4Rz2bm",
        "colab_type": "text"
      },
      "source": [
        "Minsky y Papert mostraron que una neurona del tipo LTU no puede aproximar de forma precisa una función no lineal como la compuerta XOR:\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$\n",
        "| ------------- |:-------------:| -----:|\n",
        "|0 |0 |0|\n",
        "|0 |1 |1|\n",
        "|1 |0 |1|\n",
        "|1 |1 |0|\n",
        "\n",
        "Sin embargo, es posible aproximar este tipo  combinando múltiples LTU conectadas en red. Por ejemplo, es posible llevar a cabo la operación XOR con operaciones OR, AND y NAND:\n",
        "\n",
        "$\n",
        "\t  x_1 \\text{ XOR }  x_2 = (x_1 \\lor x_2) \\land \\neg(x_1 \\land x_2)\n",
        "\t$  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucf4fSl01XTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multicapa(x, W1, b1, W2, b2):\n",
        "  escv = np.vectorize(escalon)\n",
        "  a = escv(np.dot(W1.T, x) + b1)\n",
        "  return escv(np.dot(W2.T, a) + b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OtTynPBsPax",
        "colab_type": "code",
        "outputId": "083b9785-d77a-49ef-8b94-0d065d26de35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y_xor = np.array([0., 1., 1., 0.])\n",
        "W1 = np.array([[10, -10], [10, -10]])\n",
        "b1 = np.array([-5, 15])\n",
        "\n",
        "W2 = np.array([[10], [10]])\n",
        "b2 = np.array([-15])\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "  print(multicapa(X[i], W1, b1, W2, b2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.]\n",
            "[1.]\n",
            "[1.]\n",
            "[0.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}