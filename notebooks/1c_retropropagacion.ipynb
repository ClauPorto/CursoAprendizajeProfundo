{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/1c_retropropagacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V83__FrBij1f"
   },
   "source": [
    "# Retropropagación\n",
    "\n",
    "En este *notebook* programaremos con NumPy una red neuronal densa y la entrenaremos para aproximar la operación XOR usando del gradiente descedente con el algoritmo de retropropagación. Recordemos que la operación XOR ($\\otimes$) está de la siguiente manera:\n",
    "\n",
    "| $x_1$ | $x_2$ | $y$\n",
    "| ------------- |:-------------:| -----:|\n",
    "|0 |0 |0|\n",
    "|0 |1 |1|\n",
    "|1 |0 |1|\n",
    "|1 |1 |0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xSlnjW4Oi-FP"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iAUmKI5jNuX"
   },
   "source": [
    "Nuestra red neuronal densa está compuesta por una capa de 2 entradas ($x_1$ y $x_2$), una capa oculta con 10 neuronas con función de activación sigmoide y una capa de salida con una sola neurona con función de activación sigmoide. Esta función de activación se define como:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WYhT3i68jf6x"
   },
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx6SyrPhWBrw"
   },
   "source": [
    "La función sigmoide tiene una derivada que está expresada en términos de la misma función, esto es, \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mJxvxKeAjn24"
   },
   "outputs": [],
   "source": [
    "def derivada_sigmoide(x):\n",
    "    return np.multiply(sigmoide(x), (1.0 - sigmoide(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WxI8FfLXKHv"
   },
   "source": [
    "Podemos ver la operación XOR como una tarea de clasificación binaria a partir de 2 entradas. Por lo tanto, usaremos la función de pérdida de entropía cruzada binaria:\n",
    "\n",
    "$$\n",
    "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gDjlmpAQjR3X"
   },
   "outputs": [],
   "source": [
    "def entropia_cruzada_binaria(y, p):\n",
    "    p[p == 0] = np.nextafter(0., 1.)\n",
    "    p[p == 1] = np.nextafter(1., 0.)\n",
    "    return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8nMdK-RYWMS"
   },
   "source": [
    "Asimismo, calcularemos la exactitud para medir el rendimiento del modelo aprendido por la red neuronal densa:\n",
    "\n",
    "$$\n",
    "exactitud = \\frac{correctos}{total}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8wxvZq10jIM3"
   },
   "outputs": [],
   "source": [
    "def exactitud(y, y_predicha):\n",
    "    return (y == y_predicha).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p02hAdUFZNLL"
   },
   "source": [
    "Ahora, definimos la función que propaga hacia adelante una entrada $\\mathbf{x}^{i}$. Como la red está compuesta de 2 capas densas (1 oculta y 1 de salida), tenemos 2 matrices de pesos con sus correspondientes vectores de sesgos $\\{\\mathbf{W}^{\\{1\\}}, \\mathbf{b}^{\\{1\\}}\\}$ y $\\{\\mathbf{W}^{\\{2\\}}, \\mathbf{b}^{\\{2\\}}\\}$ de la capa oculta y la capa de salida respectivamente. Así, podemos llevar a cabo la propagación hacia adelante en esta red de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\t\\begin{split}\n",
    "\t\t\t\t\\mathbf{a}^{\\{1\\}} & =  \\mathbf{x}^{(i)} \\\\\n",
    "\t\t\t\t\\mathbf{z}^{\\{2\\}} & =  \\mathbf{W}^{\\{1\\}} \\cdot \\mathbf{a}^{\\{1\\}} + \\mathbf{b}^{\\{1\\}}\\\\\n",
    "\t\t\t\t\\mathbf{a}^{\\{2\\}} & =  \\sigma(\\mathbf{z}^{\\{2\\}}) \\\\\n",
    "\t\t\t\t\\mathbf{z}^{\\{3\\}} & =  \\mathbf{W}^{\\{2\\}} \\cdot \\mathbf{a}^{\\{2\\}}  + \\mathbf{b}^{\\{2\\}}\\\\\n",
    "\t\t\t\t\\mathbf{a}^{\\{3\\}} & =  \\sigma(\\mathbf{z}^{\\{3\\}})\\\\\n",
    "\t\t\t\t\\hat{y}^{(i)} & =  \\mathbf{a}^{\\{3\\}}\n",
    "\t\t\t\\end{split}\n",
    "      $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lAsEk-zajvpX"
   },
   "outputs": [],
   "source": [
    "def hacia_adelante(x, W1, b1, W2, b2):\n",
    "    z2 = np.dot(W1.T, x[:, np.newaxis]) + b1\n",
    "    a2 = sigmoide(z2)\n",
    "    z3 = np.dot(W2.T, a2) + b2\n",
    "    y_hat = sigmoide(z3)\n",
    "    return z2, a2, z3, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiOT6jqXjzwQ"
   },
   "source": [
    "Finalmente, definimos la función para entrenar nuestra red neuronal usando gradiente descendente. Para calcular el gradiente de la función de pérdida respecto a los pesos y sesgos en cada capa empleamos el algoritmo de retropropagación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1P7i6eLgkJdg"
   },
   "outputs": [],
   "source": [
    "def retropropagacion(X, y, alpha = 0.01, n_epocas = 100, n_ocultas = 10):\n",
    "    n_ejemplos = X.shape[0]\n",
    "    n_entradas = X.shape[1]\n",
    "        \n",
    "    # Inicialización de las matrices de pesos W y V\n",
    "    W1 = np.sqrt(1.0 / n_entradas) * np.random.randn(n_entradas, n_ocultas)\n",
    "    b1 = np.zeros((n_ocultas, 1))\n",
    "    \n",
    "    W2 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, 1)\n",
    "    b2 = np.zeros((1, 1))\n",
    "    \n",
    "    perdidas = np.zeros((n_epocas))\n",
    "    exactitudes = np.zeros((n_epocas))\n",
    "    y_predicha = np.zeros((y.shape))\n",
    "    for i in range(n_epocas):\n",
    "        for j in range(n_ejemplos):\n",
    "            z2, a2, z3, y_hat = hacia_adelante(X[j], W1, b1, W2, b2)\n",
    "\n",
    "            # cálculo de gradientes para W2 y b2 por retropropagación\n",
    "            dz3 = y_hat - y[j]\n",
    "            dW2 = np.outer(a2, dz3)\n",
    "            db2 = dz3\n",
    "\n",
    "            # cálculo de gradientes para W1 y b1 por retropropagación\n",
    "            dz2 = np.dot(W2, dz3) * derivada_sigmoide(z2)\n",
    "            dW1 = np.outer(X[j], dz2)\n",
    "            db1 = dz2\n",
    "            \n",
    "            ####################################\n",
    "            # IMPORTANTE \n",
    "            # la actualización de los parámetros\n",
    "            # debe hacerse de forma simultánea\n",
    "            W2 = W2 - alpha * dW2\n",
    "            b2 = b2 - alpha * db2\n",
    "            W1 = W1 - alpha * dW1\n",
    "            b1 = b1 - alpha * db1\n",
    "\n",
    "            y_predicha[j] = y_hat\n",
    "            \n",
    "        # calcula la pérdida en la época\n",
    "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
    "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
    "        print('Epoch {0}: Pérdida = {1} Exactitud = {2}'.format(i, \n",
    "                                                              perdidas[i], \n",
    "                                                              exactitudes[i]))\n",
    "\n",
    "    return W1, W2, perdidas, exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nau0HWsrkRxg"
   },
   "source": [
    "Para probar nuestra red, generamos los ejemplos correspondientes a la operación XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8txXZ34GkUAF"
   },
   "outputs": [],
   "source": [
    "# ejemplo (XOR)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLT8avfhkYH7"
   },
   "source": [
    "Finalmente, entrenamos nuestra red con estos ejemplos por 200 épocas usando una tasa de aprendizaje $\\alpha = 1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ijKxVwZ3kbyR",
    "outputId": "85e096e7-dfc5-45c0-9e71-b7512775c50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Pérdida = 4.759342701710854 Exactitud = 25.0\n",
      "Epoch 1: Pérdida = 4.590954054596982 Exactitud = 50.0\n",
      "Epoch 2: Pérdida = 4.4120467310968845 Exactitud = 25.0\n",
      "Epoch 3: Pérdida = 4.2411690549343275 Exactitud = 25.0\n",
      "Epoch 4: Pérdida = 4.101747602832166 Exactitud = 25.0\n",
      "Epoch 5: Pérdida = 3.99322071947935 Exactitud = 25.0\n",
      "Epoch 6: Pérdida = 3.908739595255105 Exactitud = 25.0\n",
      "Epoch 7: Pérdida = 3.8410611618056363 Exactitud = 25.0\n",
      "Epoch 8: Pérdida = 3.785052250686191 Exactitud = 25.0\n",
      "Epoch 9: Pérdida = 3.7375572526301 Exactitud = 25.0\n",
      "Epoch 10: Pérdida = 3.6966571576643146 Exactitud = 25.0\n",
      "Epoch 11: Pérdida = 3.6611124774461197 Exactitud = 25.0\n",
      "Epoch 12: Pérdida = 3.630050227881158 Exactitud = 25.0\n",
      "Epoch 13: Pérdida = 3.6028044528771344 Exactitud = 25.0\n",
      "Epoch 14: Pérdida = 3.5788368437547042 Exactitud = 25.0\n",
      "Epoch 15: Pérdida = 3.5576963490499685 Exactitud = 25.0\n",
      "Epoch 16: Pérdida = 3.538997365528072 Exactitud = 50.0\n",
      "Epoch 17: Pérdida = 3.5224068408488183 Exactitud = 50.0\n",
      "Epoch 18: Pérdida = 3.5076357656710684 Exactitud = 50.0\n",
      "Epoch 19: Pérdida = 3.494432927461654 Exactitud = 50.0\n",
      "Epoch 20: Pérdida = 3.4825799111933744 Exactitud = 50.0\n",
      "Epoch 21: Pérdida = 3.4718868579962856 Exactitud = 50.0\n",
      "Epoch 22: Pérdida = 3.462188746014879 Exactitud = 50.0\n",
      "Epoch 23: Pérdida = 3.453342079899679 Exactitud = 50.0\n",
      "Epoch 24: Pérdida = 3.4452219324230056 Exactitud = 50.0\n",
      "Epoch 25: Pérdida = 3.437719306053758 Exactitud = 50.0\n",
      "Epoch 26: Pérdida = 3.4307387907480438 Exactitud = 50.0\n",
      "Epoch 27: Pérdida = 3.4241964956168016 Exactitud = 50.0\n",
      "Epoch 28: Pérdida = 3.418018231138607 Exactitud = 50.0\n",
      "Epoch 29: Pérdida = 3.4121379174131703 Exactitud = 50.0\n",
      "Epoch 30: Pérdida = 3.4064961934921243 Exactitud = 50.0\n",
      "Epoch 31: Pérdida = 3.401039203288043 Exactitud = 50.0\n",
      "Epoch 32: Pérdida = 3.395717534848915 Exactitud = 50.0\n",
      "Epoch 33: Pérdida = 3.3904852916877273 Exactitud = 50.0\n",
      "Epoch 34: Pérdida = 3.385299277168504 Exactitud = 50.0\n",
      "Epoch 35: Pérdida = 3.3801182755070833 Exactitud = 50.0\n",
      "Epoch 36: Pérdida = 3.3749024156381022 Exactitud = 50.0\n",
      "Epoch 37: Pérdida = 3.3696126069712293 Exactitud = 50.0\n",
      "Epoch 38: Pérdida = 3.364210038892513 Exactitud = 50.0\n",
      "Epoch 39: Pérdida = 3.3586557387721476 Exactitud = 50.0\n",
      "Epoch 40: Pérdida = 3.352910186243977 Exactitud = 50.0\n",
      "Epoch 41: Pérdida = 3.3469329846517315 Exactitud = 50.0\n",
      "Epoch 42: Pérdida = 3.3406825938253326 Exactitud = 50.0\n",
      "Epoch 43: Pérdida = 3.3341161317390053 Exactitud = 50.0\n",
      "Epoch 44: Pérdida = 3.3271892560422507 Exactitud = 50.0\n",
      "Epoch 45: Pérdida = 3.319856139803386 Exactitud = 50.0\n",
      "Epoch 46: Pérdida = 3.3120695588275604 Exactitud = 50.0\n",
      "Epoch 47: Pérdida = 3.3037811102586367 Exactitud = 50.0\n",
      "Epoch 48: Pérdida = 3.294941583376885 Exactitud = 50.0\n",
      "Epoch 49: Pérdida = 3.2855015029779553 Exactitud = 50.0\n",
      "Epoch 50: Pérdida = 3.2754118628004703 Exactitud = 50.0\n",
      "Epoch 51: Pérdida = 3.2646250604911167 Exactitud = 50.0\n",
      "Epoch 52: Pérdida = 3.253096035997565 Exactitud = 50.0\n",
      "Epoch 53: Pérdida = 3.2407836017683347 Exactitud = 50.0\n",
      "Epoch 54: Pérdida = 3.227651935873598 Exactitud = 50.0\n",
      "Epoch 55: Pérdida = 3.21367218893455 Exactitud = 50.0\n",
      "Epoch 56: Pérdida = 3.1988241341188957 Exactitud = 50.0\n",
      "Epoch 57: Pérdida = 3.183097768772047 Exactitud = 50.0\n",
      "Epoch 58: Pérdida = 3.1664947595011492 Exactitud = 50.0\n",
      "Epoch 59: Pérdida = 3.1490296130173707 Exactitud = 50.0\n",
      "Epoch 60: Pérdida = 3.130730455867167 Exactitud = 50.0\n",
      "Epoch 61: Pérdida = 3.111639319593274 Exactitud = 50.0\n",
      "Epoch 62: Pérdida = 3.091811854622275 Exactitud = 50.0\n",
      "Epoch 63: Pérdida = 3.071316435067618 Exactitud = 50.0\n",
      "Epoch 64: Pérdida = 3.050232664303763 Exactitud = 50.0\n",
      "Epoch 65: Pérdida = 3.0286493423347247 Exactitud = 50.0\n",
      "Epoch 66: Pérdida = 3.006662004152053 Exactitud = 50.0\n",
      "Epoch 67: Pérdida = 2.9843701768052657 Exactitud = 50.0\n",
      "Epoch 68: Pérdida = 2.961874526249 Exactitud = 50.0\n",
      "Epoch 69: Pérdida = 2.939274069897512 Exactitud = 50.0\n",
      "Epoch 70: Pérdida = 2.9166636169001388 Exactitud = 50.0\n",
      "Epoch 71: Pérdida = 2.894131568188712 Exactitud = 50.0\n",
      "Epoch 72: Pérdida = 2.8717581674868775 Exactitud = 50.0\n",
      "Epoch 73: Pérdida = 2.8496142491084293 Exactitud = 50.0\n",
      "Epoch 74: Pérdida = 2.827760484808438 Exactitud = 50.0\n",
      "Epoch 75: Pérdida = 2.8062470952408463 Exactitud = 50.0\n",
      "Epoch 76: Pérdida = 2.785113964832152 Exactitud = 50.0\n",
      "Epoch 77: Pérdida = 2.764391083129123 Exactitud = 50.0\n",
      "Epoch 78: Pérdida = 2.74409923017347 Exactitud = 50.0\n",
      "Epoch 79: Pérdida = 2.7242508262629466 Exactitud = 50.0\n",
      "Epoch 80: Pérdida = 2.7048508750938476 Exactitud = 50.0\n",
      "Epoch 81: Pérdida = 2.6858979412583617 Exactitud = 50.0\n",
      "Epoch 82: Pérdida = 2.66738511626703 Exactitud = 50.0\n",
      "Epoch 83: Pérdida = 2.6493009400957477 Exactitud = 50.0\n",
      "Epoch 84: Pérdida = 2.6316302566964946 Exactitud = 50.0\n",
      "Epoch 85: Pérdida = 2.6143549914318767 Exactitud = 50.0\n",
      "Epoch 86: Pérdida = 2.5974548458410993 Exactitud = 50.0\n",
      "Epoch 87: Pérdida = 2.580907910615343 Exactitud = 50.0\n",
      "Epoch 88: Pérdida = 2.564691201391569 Exactitud = 50.0\n",
      "Epoch 89: Pérdida = 2.548781124263022 Exactitud = 50.0\n",
      "Epoch 90: Pérdida = 2.5331538790526285 Exactitud = 50.0\n",
      "Epoch 91: Pérdida = 2.5177858086733944 Exactitud = 50.0\n",
      "Epoch 92: Pérdida = 2.502653702534067 Exactitud = 50.0\n",
      "Epoch 93: Pérdida = 2.4877350611166595 Exactitud = 50.0\n",
      "Epoch 94: Pérdida = 2.473008327688671 Exactitud = 50.0\n",
      "Epoch 95: Pérdida = 2.4584530917139595 Exactitud = 50.0\n",
      "Epoch 96: Pérdida = 2.4440502669625213 Exactitud = 50.0\n",
      "Epoch 97: Pérdida = 2.42978224564397 Exactitud = 50.0\n",
      "Epoch 98: Pérdida = 2.4156330281466807 Exactitud = 50.0\n",
      "Epoch 99: Pérdida = 2.4015883261977207 Exactitud = 50.0\n",
      "Epoch 100: Pérdida = 2.3876356355135737 Exactitud = 50.0\n",
      "Epoch 101: Pérdida = 2.373764272338148 Exactitud = 50.0\n",
      "Epoch 102: Pérdida = 2.3599653667121734 Exactitud = 50.0\n",
      "Epoch 103: Pérdida = 2.346231803927118 Exactitud = 50.0\n",
      "Epoch 104: Pérdida = 2.3325581044020556 Exactitud = 50.0\n",
      "Epoch 105: Pérdida = 2.3189402311502256 Exactitud = 50.0\n",
      "Epoch 106: Pérdida = 2.30537531296165 Exactitud = 50.0\n",
      "Epoch 107: Pérdida = 2.2918612701914514 Exactitud = 50.0\n",
      "Epoch 108: Pérdida = 2.278396328222259 Exactitud = 50.0\n",
      "Epoch 109: Pérdida = 2.2649784006596683 Exactitud = 50.0\n",
      "Epoch 110: Pérdida = 2.2516043192340196 Exactitud = 50.0\n",
      "Epoch 111: Pérdida = 2.2382688789518466 Exactitud = 50.0\n",
      "Epoch 112: Pérdida = 2.2249636534763795 Exactitud = 50.0\n",
      "Epoch 113: Pérdida = 2.2116755144876024 Exactitud = 50.0\n",
      "Epoch 114: Pérdida = 2.198384756265128 Exactitud = 50.0\n",
      "Epoch 115: Pérdida = 2.1850626777454054 Exactitud = 50.0\n",
      "Epoch 116: Pérdida = 2.1716684013223464 Exactitud = 50.0\n",
      "Epoch 117: Pérdida = 2.1581446000665996 Exactitud = 50.0\n",
      "Epoch 118: Pérdida = 2.144411648624727 Exactitud = 50.0\n",
      "Epoch 119: Pérdida = 2.1303594914016575 Exactitud = 50.0\n",
      "Epoch 120: Pérdida = 2.115836223627094 Exactitud = 50.0\n",
      "Epoch 121: Pérdida = 2.100632025958033 Exactitud = 50.0\n",
      "Epoch 122: Pérdida = 2.0844568024497727 Exactitud = 50.0\n",
      "Epoch 123: Pérdida = 2.066910048298624 Exactitud = 50.0\n",
      "Epoch 124: Pérdida = 2.047443207480847 Exactitud = 50.0\n",
      "Epoch 125: Pérdida = 2.0253205650007593 Exactitud = 50.0\n",
      "Epoch 126: Pérdida = 1.99959897788775 Exactitud = 50.0\n",
      "Epoch 127: Pérdida = 1.969172951808426 Exactitud = 50.0\n",
      "Epoch 128: Pérdida = 1.9329564169272269 Exactitud = 50.0\n",
      "Epoch 129: Pérdida = 1.8902321601453456 Exactitud = 75.0\n",
      "Epoch 130: Pérdida = 1.8410023907993036 Exactitud = 75.0\n",
      "Epoch 131: Pérdida = 1.7859647360653201 Exactitud = 75.0\n",
      "Epoch 132: Pérdida = 1.726043963460494 Exactitud = 75.0\n",
      "Epoch 133: Pérdida = 1.6620449615926927 Exactitud = 75.0\n",
      "Epoch 134: Pérdida = 1.594748452402479 Exactitud = 75.0\n",
      "Epoch 135: Pérdida = 1.5250801645580956 Exactitud = 75.0\n",
      "Epoch 136: Pérdida = 1.4540960271226524 Exactitud = 75.0\n",
      "Epoch 137: Pérdida = 1.3828666943066037 Exactitud = 75.0\n",
      "Epoch 138: Pérdida = 1.3123649142729636 Exactitud = 100.0\n",
      "Epoch 139: Pérdida = 1.2433933029233828 Exactitud = 100.0\n",
      "Epoch 140: Pérdida = 1.1765598411540892 Exactitud = 100.0\n",
      "Epoch 141: Pérdida = 1.1122922976312708 Exactitud = 100.0\n",
      "Epoch 142: Pérdida = 1.0508735788423558 Exactitud = 100.0\n",
      "Epoch 143: Pérdida = 0.9924802380354685 Exactitud = 100.0\n",
      "Epoch 144: Pérdida = 0.9372131422938454 Exactitud = 100.0\n",
      "Epoch 145: Pérdida = 0.8851171267157303 Exactitud = 100.0\n",
      "Epoch 146: Pérdida = 0.8361917064685609 Exactitud = 100.0\n",
      "Epoch 147: Pérdida = 0.790396789399716 Exactitud = 100.0\n",
      "Epoch 148: Pérdida = 0.7476568373571196 Exactitud = 100.0\n",
      "Epoch 149: Pérdida = 0.7078654728360971 Exactitud = 100.0\n",
      "Epoch 150: Pérdida = 0.6708911368500886 Exactitud = 100.0\n",
      "Epoch 151: Pérdida = 0.6365835201585632 Exactitud = 100.0\n",
      "Epoch 152: Pérdida = 0.6047801400974373 Exactitud = 100.0\n",
      "Epoch 153: Pérdida = 0.5753124526617598 Exactitud = 100.0\n",
      "Epoch 154: Pérdida = 0.5480110807056843 Exactitud = 100.0\n",
      "Epoch 155: Pérdida = 0.5227099629267835 Exactitud = 100.0\n",
      "Epoch 156: Pérdida = 0.4992494105164765 Exactitud = 100.0\n",
      "Epoch 157: Pérdida = 0.47747817585119856 Exactitud = 100.0\n",
      "Epoch 158: Pérdida = 0.4572546957377372 Exactitud = 100.0\n",
      "Epoch 159: Pérdida = 0.4384476867629614 Exactitud = 100.0\n",
      "Epoch 160: Pérdida = 0.4209362591822107 Exactitud = 100.0\n",
      "Epoch 161: Pérdida = 0.4046096918472771 Exactitud = 100.0\n",
      "Epoch 162: Pérdida = 0.3893669827899999 Exactitud = 100.0\n",
      "Epoch 163: Pérdida = 0.3751162633297659 Exactitud = 100.0\n",
      "Epoch 164: Pérdida = 0.36177414038713807 Exactitud = 100.0\n",
      "Epoch 165: Pérdida = 0.34926501283516526 Exactitud = 100.0\n",
      "Epoch 166: Pérdida = 0.33752039307606596 Exactitud = 100.0\n",
      "Epoch 167: Pérdida = 0.32647825405025643 Exactitud = 100.0\n",
      "Epoch 168: Pérdida = 0.3160824138932615 Exactitud = 100.0\n",
      "Epoch 169: Pérdida = 0.3062819647991559 Exactitud = 100.0\n",
      "Epoch 170: Pérdida = 0.2970307487575168 Exactitud = 100.0\n",
      "Epoch 171: Pérdida = 0.28828688023995613 Exactitud = 100.0\n",
      "Epoch 172: Pérdida = 0.2800123142591566 Exactitud = 100.0\n",
      "Epoch 173: Pérdida = 0.2721724572324831 Exactitud = 100.0\n",
      "Epoch 174: Pérdida = 0.26473581754951303 Exactitud = 100.0\n",
      "Epoch 175: Pérdida = 0.2576736925196712 Exactitud = 100.0\n",
      "Epoch 176: Pérdida = 0.250959888356178 Exactitud = 100.0\n",
      "Epoch 177: Pérdida = 0.24457046996078674 Exactitud = 100.0\n",
      "Epoch 178: Pérdida = 0.23848353745818107 Exactitud = 100.0\n",
      "Epoch 179: Pérdida = 0.23267902665403073 Exactitud = 100.0\n",
      "Epoch 180: Pérdida = 0.2271385308327113 Exactitud = 100.0\n",
      "Epoch 181: Pérdida = 0.22184514155427412 Exactitud = 100.0\n",
      "Epoch 182: Pérdida = 0.21678330634572096 Exactitud = 100.0\n",
      "Epoch 183: Pérdida = 0.21193870140327253 Exactitud = 100.0\n",
      "Epoch 184: Pérdida = 0.20729811762723577 Exactitud = 100.0\n",
      "Epoch 185: Pérdida = 0.20284935849795457 Exactitud = 100.0\n",
      "Epoch 186: Pérdida = 0.1985811484701554 Exactitud = 100.0\n",
      "Epoch 187: Pérdida = 0.19448305071443572 Exactitud = 100.0\n",
      "Epoch 188: Pérdida = 0.19054539316970565 Exactitud = 100.0\n",
      "Epoch 189: Pérdida = 0.18675920199039603 Exactitud = 100.0\n",
      "Epoch 190: Pérdida = 0.18311614157852282 Exactitud = 100.0\n",
      "Epoch 191: Pérdida = 0.17960846048464113 Exactitud = 100.0\n",
      "Epoch 192: Pérdida = 0.17622894254457286 Exactitud = 100.0\n",
      "Epoch 193: Pérdida = 0.17297086269185247 Exactitud = 100.0\n",
      "Epoch 194: Pérdida = 0.16982794695016878 Exactitud = 100.0\n",
      "Epoch 195: Pérdida = 0.16679433616670325 Exactitud = 100.0\n",
      "Epoch 196: Pérdida = 0.16386455309715628 Exactitud = 100.0\n",
      "Epoch 197: Pérdida = 0.16103347249714028 Exactitud = 100.0\n",
      "Epoch 198: Pérdida = 0.15829629391329764 Exactitud = 100.0\n",
      "Epoch 199: Pérdida = 0.15564851690157389 Exactitud = 100.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "W1, W2, perdidas, exactitudes = retropropagacion(X, \n",
    "                                                 y, \n",
    "                                                 alpha = 1.0, \n",
    "                                                 n_epocas = 200,\n",
    "                                                 n_ocultas = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8A3KZ5JkDJ3"
   },
   "source": [
    "Graficamos el valor de la pérdida y la exactitud en cada época para ver el comportamiento de nuestra red durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yglJSF9nkR7k",
    "outputId": "3339598f-a87a-469b-8499-bc16add9a559"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(perdidas.size), perdidas, label='ECB')\n",
    "plt.plot(np.arange(exactitudes.size), exactitudes, label='Exactitud')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hz0OaZtsCCgs"
   },
   "source": [
    "## Inicializando los pesos con zeros\n",
    "Como se mencionó anteriormente, las matrices de pesos $\\mathbf{W^{\\{1\\}}}$ y $\\mathbf{W^{\\{2\\}}}$ se initializan con valores aleatorios pequeños mientras que los vectores de sesgo $\\mathbf{b^{\\{1\\}}}$ y $\\mathbf{b^{\\{1\\}}}$ con zeros. Examinemos qué pasa si inicializamos las matrices de pesos con zeros. Observa los valores de los pesos en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FHaavbWGzqzg"
   },
   "outputs": [],
   "source": [
    "def retropropagacion_zeros(X, y, alpha = 0.1, n_epocas = 100, n_ocultas = 10):\n",
    "    n_ejemplos = X.shape[0]\n",
    "    n_entradas = X.shape[1]\n",
    "    \n",
    "    # Inicializa matrices de pesos W1 y W2 y vectores de sesgos b1 y b2\n",
    "    W1 = np.zeros((n_entradas, n_ocultas))\n",
    "    b1 = np.zeros((n_ocultas, 1)) \n",
    "    W2 = np.zeros((n_ocultas, 1))\n",
    "    b2 = np.zeros((1, 1))\n",
    "    \n",
    "    perdidas = np.zeros((n_epocas))\n",
    "    exactitudes = np.zeros((n_epocas))\n",
    "    y_predicha = np.zeros((y.shape))\n",
    "    for i in range(n_epocas):\n",
    "        for j in range(n_ejemplos):\n",
    "            z2, a2, z3, y_hat = hacia_adelante(X[j], W1, b1, W2, b2)\n",
    "\n",
    "            # cálculo de gradiente para W2 por retropropagación\n",
    "            delta3 = (y[j] - y_hat) * derivada_sigmoide(z3)\n",
    "            W2 = W2 - alpha * np.outer(a2, delta3)\n",
    "            b2 = b2 - alpha * delta3\n",
    "            \n",
    "            # calculo de gradiente para W1 por retropropagación\n",
    "            delta2 = np.dot(W2, delta3) * derivada_sigmoide(z2)\n",
    "            W1 = W1 - alpha * np.outer(X[j], delta2)\n",
    "            b1 = b1 - alpha * delta2\n",
    "            \n",
    "            y_predicha[j] = y_hat\n",
    "            \n",
    "        # calcula la pérdida en época\n",
    "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
    "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
    "        print('Epoch {0}: Pérdida = {1} Exactitud = {2}'.format(i, \n",
    "                                                              perdidas[i], \n",
    "                                                              exactitudes[i]))\n",
    "        print('W1 = {0}'.format(W1))\n",
    "        print('W2 = {0}'.format(W2))\n",
    "            \n",
    "    return W1, W2, perdidas, exactitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jr1HownICHf9",
    "outputId": "557c44b1-31ad-47e8-e487-10dcbd42672b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Pérdida = 2.383938269247035 Exactitud = 100.0\n",
      "W1 = [[ 0.0015006   0.0015006   0.0015006   0.0015006   0.0015006   0.0015006\n",
      "   0.0015006   0.0015006   0.0015006   0.0015006 ]\n",
      " [-0.00013937 -0.00013937 -0.00013937 -0.00013937 -0.00013937 -0.00013937\n",
      "  -0.00013937 -0.00013937 -0.00013937 -0.00013937]]\n",
      "W2 = [[0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]]\n",
      "Epoch 1: Pérdida = 2.3940150790588524 Exactitud = 75.0\n",
      "W1 = [[3.07843345e-03 3.07843345e-03 3.07843345e-03 3.07843345e-03\n",
      "  3.07843345e-03 3.07843345e-03 3.07843345e-03 3.07843345e-03\n",
      "  3.07843345e-03 3.07843345e-03]\n",
      " [6.32326402e-05 6.32326402e-05 6.32326402e-05 6.32326402e-05\n",
      "  6.32326402e-05 6.32326402e-05 6.32326402e-05 6.32326402e-05\n",
      "  6.32326402e-05 6.32326402e-05]]\n",
      "W2 = [[0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]]\n",
      "Epoch 2: Pérdida = 2.454375736775318 Exactitud = 50.0\n",
      "W1 = [[0.00535668 0.00535668 0.00535668 0.00535668 0.00535668 0.00535668\n",
      "  0.00535668 0.00535668 0.00535668 0.00535668]\n",
      " [0.00153339 0.00153339 0.00153339 0.00153339 0.00153339 0.00153339\n",
      "  0.00153339 0.00153339 0.00153339 0.00153339]]\n",
      "W2 = [[0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]]\n",
      "Epoch 3: Pérdida = 2.7471355126181987 Exactitud = 50.0\n",
      "W1 = [[0.01036404 0.01036404 0.01036404 0.01036404 0.01036404 0.01036404\n",
      "  0.01036404 0.01036404 0.01036404 0.01036404]\n",
      " [0.00645381 0.00645381 0.00645381 0.00645381 0.00645381 0.00645381\n",
      "  0.00645381 0.00645381 0.00645381 0.00645381]]\n",
      "W2 = [[0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]]\n",
      "Epoch 4: Pérdida = 3.5902678548185696 Exactitud = 50.0\n",
      "W1 = [[0.01745773 0.01745773 0.01745773 0.01745773 0.01745773 0.01745773\n",
      "  0.01745773 0.01745773 0.01745773 0.01745773]\n",
      " [0.01361346 0.01361346 0.01361346 0.01361346 0.01361346 0.01361346\n",
      "  0.01361346 0.01361346 0.01361346 0.01361346]]\n",
      "W2 = [[0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]]\n"
     ]
    }
   ],
   "source": [
    "W1, W2, perdidas, exactitudes = retropropagacion_zeros(X, \n",
    "                                                       y, \n",
    "                                                       alpha = 1.0,\n",
    "                                                       n_epocas = 5,\n",
    "                                                       n_ocultas = 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1c_retropropagacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
