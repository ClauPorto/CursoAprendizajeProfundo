{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/3a_rnn_class_last_step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reconocimiento de acciones con CNN + RNN\n",
    "\n",
    "#### <div style=\"text-align: right\"> Berenice Montalvo Lezama </div>\n",
    "\n",
    "En este ejemplo veremos como realizar reconocimiento de acciones sobre [UCF11](https://www.crcv.ucf.edu/data/UCF_YouTube_Action.php) un conjunto de referencia en analisis de video recolectado por el [Center for Research in Computer Vision](https://www.crcv.ucf.edu/) de la Universidad de Central del Florida. UCF11 es un cunjunto multiclase con 1600 videos en 11 diferentes de acciones humanas. \n",
    "\n",
    "La arquitectura que se presenta en este ejemplo esta compuesta por una red neuronal convolucional y una recurrente. Para otorgar la clasificación de un video se toma la última salida de la red recurrente.\n",
    "\n",
    "\n",
    "![UCF11](../figs/UCF11.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Carga de datos\n",
    "\n",
    "### 1.1 Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "tf.random.set_seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Descarga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ucf11_frames_reps_rn50v2_pca_std.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.get_file('ucf11_frames_reps_rn50v2_pca_std.tfrecords',\n",
    "    'https://cloud.xibalba.com.mx/s/PFZWERd9MdHoLpz/download',\n",
    "    cache_subdir='datasets/ucf11')\n",
    "!ls ~/.keras/datasets/ucf11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tuberia de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _parse_function at 0x7f361d868d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function _parse_function at 0x7f361d868d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/bere/.virtualenvs/cap-gpu/lib/python3.6/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "x.shape=(64, 50, 512)\n",
      "x[0, :5, :5]=\n",
      "[-0.36228782 -1.3095968   1.1650468   0.59512883  1.4917995  -0.36076042\n",
      " -1.3810619   1.2208297   0.62461144  1.6224496  -0.35992855 -1.377344\n",
      "  1.2155812   0.618533    1.6204273  -0.3592346  -1.3868256   1.2387475\n",
      "  0.624294    1.6373067  -0.36634874 -1.3755231   1.238343    0.60989845\n",
      "  1.6211106 ]\n",
      "y_true.shape=(64,)\n",
      "y_true[0]=3\n",
      "name.shape=(64,)\n",
      "name[0]=b'golf_swing/v_golf_03/v_golf_03_04'\n"
     ]
    }
   ],
   "source": [
    "# se crea un diccionario para la descripción de los ejemplos\n",
    "_feat_desc = {\n",
    "  'x': tf.io.VarLenFeature(tf.float32),\n",
    "  'y': tf.io.FixedLenFeature([], tf.int64),\n",
    "  'name': tf.io.FixedLenFeature([], tf.string)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  se = tf.io.parse_single_example(example_proto, _feat_desc)\n",
    "  x = tf.reshape(tf.sparse.to_dense(se['x']), (50, -1))\n",
    "  y = se['y']\n",
    "  name = se['name']\n",
    "  return x, y, name\n",
    "\n",
    "# ruta de los TFRecords con las representaciones espaciales \n",
    "ds_path = '~/.keras/datasets/ucf11/ucf11_frames_reps_rn50v2_pca_std.tfrecords'\n",
    "ds_path = os.path.expanduser(ds_path)\n",
    "shuffle_size = 1593\n",
    "batch_size = 64\n",
    "\n",
    "# se crea un TFRecordDataset para los TFRecords con las representaciones espaciales \n",
    "train_ds = tf.data.TFRecordDataset(ds_path)\n",
    "# se obtienen las representaciones espaciales de los ejemplos\n",
    "train_ds = train_ds.map(_parse_function)\n",
    "# se barajea el conjunto\n",
    "train_ds = train_ds.shuffle(shuffle_size)\n",
    "# se contruyen los lotes \n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "for x, y_true, name in train_ds.take(1):\n",
    "    print(f'x.shape={x.shape}')\n",
    "    print('x[0, :5, :5]=')\n",
    "    print(x[0, :5, :5].numpy().flatten())\n",
    "    print(f'y_true.shape={y_true.shape}')\n",
    "    print(f'y_true[0]={y_true[0].numpy()}')\n",
    "    print(f'name.shape={name.shape}')\n",
    "    print(f'name[0]={name[0].numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Definición del modelo\n",
    "\n",
    "![Arquitectura](../figs/rnn_last_step.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNNLS(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(CRNNLS, self).__init__()\n",
    "    self.rl = GRU(32, name='rl')\n",
    "    self.fc = Dense(11, activation='softmax', name='fc')\n",
    "\n",
    "  def call(self, x):\n",
    "    # (N, 50, 512) =>\n",
    "    # (N, 32)\n",
    "    x = self.rl(x)\n",
    "    # (N, 32) =>\n",
    "    # (N, 11)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Entrenamiento\n",
    "\n",
    "### 3.1 Función de pérdida y optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropía cruzada binaria\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# gradiente descendente\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Métricas: pérdida y exactitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historiales a nivel época\n",
    "loss_epoch = tf.keras.metrics.Mean()\n",
    "acc_epoch = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# historiales a nivel entrenamiento\n",
    "loss_history = []\n",
    "acc_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ciclo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig model 190923-212006\n",
      "  0 loss=262.90, acc=  9.72\n",
      "  1 loss=256.24, acc= 11.35\n",
      "  2 loss=250.44, acc= 12.48\n",
      "  3 loss=244.85, acc= 13.67\n",
      "  4 loss=239.30, acc= 15.55\n",
      "  5 loss=233.95, acc= 17.30\n",
      "  6 loss=228.85, acc= 19.50\n",
      "  7 loss=223.73, acc= 22.01\n",
      "  8 loss=218.76, acc= 23.89\n",
      "  9 loss=213.98, acc= 26.08\n",
      " 10 loss=209.25, acc= 27.84\n",
      " 11 loss=204.61, acc= 29.91\n",
      " 12 loss=200.01, acc= 32.29\n",
      " 13 loss=195.53, acc= 35.24\n",
      " 14 loss=191.16, acc= 37.37\n",
      " 15 loss=186.88, acc= 39.81\n",
      " 16 loss=182.60, acc= 41.94\n",
      " 17 loss=178.38, acc= 44.58\n",
      " 18 loss=174.29, acc= 47.02\n",
      " 19 loss=170.21, acc= 49.34\n",
      " 20 loss=166.27, acc= 52.29\n",
      " 21 loss=162.36, acc= 54.29\n",
      " 22 loss=158.56, acc= 56.74\n",
      " 23 loss=154.69, acc= 58.56\n",
      " 24 loss=151.01, acc= 61.07\n",
      " 25 loss=147.33, acc= 63.07\n",
      " 26 loss=143.77, acc= 65.14\n",
      " 27 loss=140.15, acc= 66.90\n",
      " 28 loss=136.68, acc= 68.09\n",
      " 29 loss=133.30, acc= 69.28\n",
      " 30 loss=129.94, acc= 71.60\n",
      " 31 loss=126.61, acc= 72.98\n",
      " 32 loss=123.44, acc= 74.61\n",
      " 33 loss=120.22, acc= 76.11\n",
      " 34 loss=117.19, acc= 77.12\n",
      " 35 loss=114.12, acc= 78.06\n",
      " 36 loss=111.09, acc= 79.62\n",
      " 37 loss=108.15, acc= 80.25\n",
      " 38 loss=105.30, acc= 81.07\n",
      " 39 loss=102.51, acc= 82.76\n",
      " 40 loss= 99.84, acc= 83.70\n",
      " 41 loss= 97.11, acc= 84.33\n",
      " 42 loss= 94.54, acc= 85.20\n",
      " 43 loss= 92.01, acc= 85.96\n",
      " 44 loss= 89.46, acc= 86.52\n",
      " 45 loss= 87.10, acc= 87.40\n",
      " 46 loss= 84.71, acc= 87.84\n",
      " 47 loss= 82.38, acc= 88.65\n",
      " 48 loss= 80.20, acc= 89.34\n",
      " 49 loss= 77.96, acc= 89.97\n"
     ]
    }
   ],
   "source": [
    "# instanciamos el modelo\n",
    "model = CRNNLS()\n",
    "\n",
    "model_name = datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "train_dir = f'logs/{model_name}/train'\n",
    "train_writer = tf.summary.create_file_writer(train_dir)\n",
    "print(f\"Trainig model {model_name}\")\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    for step, (x, y_true, _) in enumerate(train_ds):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        loss_epoch(loss)\n",
    "        acc_epoch(y_true, y_pred)\n",
    "\n",
    "    loss_val = loss_epoch.result().numpy() * 100\n",
    "    acc_val = acc_epoch.result().numpy() * 100\n",
    "    loss_epoch.reset_states()\n",
    "    acc_epoch.reset_states()\n",
    "    \n",
    "    with train_writer.as_default():\n",
    "        tf.summary.scalar('loss', loss_val, epoch)\n",
    "        tf.summary.scalar('acc', acc_val, epoch)\n",
    "    \n",
    "    print(f'{epoch:3d} loss={loss_val:6.2f}, acc={acc_val:6.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
