{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/7a_dcgan_cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de imágenes usando DCGAN\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\"> Bere et Richardt </div>\n",
    "\n",
    "---\n",
    "\n",
    "En esta libreta veremos un ejemplo de generación de imágenes utilizando una red generativa adversaria en PyTorch basado en *[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "](https://arxiv.org/abs/1511.06434)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ny0L2LzogTN-"
   },
   "outputs": [],
   "source": [
    "# funciones aleatorias\n",
    "import random\n",
    "\n",
    "# gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "# arreglos multidimensionales\n",
    "import numpy as np\n",
    "# redes neuronales\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# imágenes\n",
    "from skimage import io\n",
    "# redes neuronales\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "# barras de progreso\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# reproducibilidad\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid(xs, rows, cols, figsize=(12, 6)):\n",
    "    \"\"\"Despliega un ejempos en una cuadrícula.\"\"\"\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=figsize)\n",
    "    i = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax[r, c].imshow(xs[i])\n",
    "            ax[r, c].set_xticklabels([])\n",
    "            ax[r, c].set_yticklabels([])\n",
    "            i += 1\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_batch(x, rows, cols, figsize=(12, 6)):\n",
    "    \"\"\"Despliega un lote en una cuadrícula.\"\"\"\n",
    "    # denormalizamos\n",
    "    for c, (mean, std) in enumerate(zip(MEAN, STD)):\n",
    "        x[:, c] = x[:, c] * std + mean \n",
    "    x *= 255\n",
    "    # rotamos canales\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    # convertimos a entero\n",
    "    x = (x.numpy()).astype(np.uint8)\n",
    "\n",
    "    display_grid(x, rows, cols, figsize)\n",
    "\n",
    "    \n",
    "def weights_init(m):\n",
    "    \"\"\"Iniciliza\"\"\"\n",
    "    # del artículo de DCGAN [1]\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    \n",
    "class SequentialDebug(nn.Sequential):\n",
    "\n",
    "    def forward(self, input):\n",
    "        for step, module in enumerate(self):\n",
    "            print(f'{step} {input.shape}')\n",
    "            input = module(input)\n",
    "        print(f'{step + 1} {input.shape}')\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjKxreAkoZeT"
   },
   "source": [
    "## 2 Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tuberias de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio de datos\n",
    "DATA_DIR = '../data'\n",
    "# media y desviación estandar \n",
    "MEAN = (0.5, 0.5, 0.5)\n",
    "STD = (0.5, 0.5, 0.5)\n",
    "# filas y columnas de la cuadricula \n",
    "ROWS, COLS = 4, 8\n",
    "# tamaño del lote\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# transformaciones para la imagen\n",
    "tsfm = transforms.Compose([\n",
    "    # convertimos a torch.Tensor y escalamos a [0,1]\n",
    "    transforms.ToTensor(),\n",
    "    # estandarizamos: restamos la media y dividimos sobre la varianza\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# creamos un Dataset\n",
    "ds = CIFAR10(\n",
    "    # directorio de datos\n",
    "    root=DATA_DIR,\n",
    "    # subconjunto de entrenamiento\n",
    "    train=True,\n",
    "    # descarga de datos\n",
    "    download=True,\n",
    "    # transformación\n",
    "    transform=tsfm\n",
    ")\n",
    "\n",
    "# creamos el cargador de datos\n",
    "dl = DataLoader(\n",
    "    # conjunto\n",
    "    ds,\n",
    "    # tamaño del lote\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # desordenar\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# desplegamos un lote de imágenes\n",
    "x, _ = next(iter(dl))\n",
    "print(f'x shape={x.shape} dtype={x.dtype}')\n",
    "display_batch(x, ROWS, COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definición de red generadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # [N, 100, 1, 1] => [N, 3, 64, 64]\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            # [N, 100, 1, 1] => [N, 256, 4, 4]\n",
    "            nn.ConvTranspose2d(100, 256, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # [N, 256, 4, 4] => [N, 128, 8, 8]\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # [N, 128, 8, 8] => [N, 64, 16, 16]\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # [N, 64, 32, 32] => [N, 3, 32, 32]\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "z = torch.zeros(1, 100, 1, 1)\n",
    "x = Generator()(z)\n",
    "f'{z.shape} => {x.shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Definición de red discriminadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "#         self.net = SequentialDebug(\n",
    "\n",
    "            # [N, 3, 32, 32] => [N, 32, 16, 16]\n",
    "            nn.Conv2d(3, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # [N, 32, 16, 16] => [N, 64, 8, 8]\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # [N, 64, 8, 8] => [N, 128, 4, 4]\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # [N, 128, 4, 4] => [N, 1, 1, 1]\n",
    "            nn.Conv2d(128, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "            \n",
    "            # [N, 1, 1, 1] => [N, 1]\n",
    "            nn.Flatten(),\n",
    "        )       \n",
    "\n",
    "    # metodo para inferencia\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "x = torch.zeros(1, 3, 32, 32)\n",
    "y = Discriminator()(x)\n",
    "f'{x.shape} => {y.shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Ciclo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(imgs, batch_size, label, dis, device):\n",
    "    \"\"\"Propaga hacía adelante un lote de imágenes sobre la discriminadora \n",
    "       y retropropaga la gráfica de cómputo.\"\"\"\n",
    "    # creamos etiquetas\n",
    "    y_true = torch.full([batch_size], label, dtype=torch.float, device=device)\n",
    "    # predecimos etiquetas\n",
    "    y_pred = dis(imgs).view(-1)\n",
    "    # calculamos la pérdida\n",
    "    loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "    # retropropagamos para la discriminadora\n",
    "    loss.backward()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train(dl, gen, dis,\n",
    "          fake_label=0, real_label=1, epochs=50,\n",
    "          # hiperparámetros del artículo\n",
    "          beta1=0.5, lr=0.0002, z_size=100,\n",
    "          fake_imgs_save_freq=5,\n",
    "    ):\n",
    "    \"\"\"Entrena la redes discriminadora y generadora.\"\"\"\n",
    "    \n",
    "    # inicializamos redes\n",
    "    gen.apply(weights_init)\n",
    "    dis.apply(weights_init)\n",
    "\n",
    "    # movemos a dispositivo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gen.to(device)\n",
    "    dis.to(device)\n",
    "\n",
    "    # optimizadores\n",
    "    gen_opt = optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    dis_opt = optim.Adam(dis.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    # historiales de pérdidas\n",
    "    gen_losses, dis_losses = [], []\n",
    "    fake_imgs_hist = []\n",
    "\n",
    "    # ciclo de entrenamiento\n",
    "    for epoch in trange(epochs):\n",
    "        \n",
    "        epoch_gen_losses, epoch_dis_losses = [], []\n",
    "        \n",
    "        for real_imgs, _ in dl:\n",
    "\n",
    "            batch_size = real_imgs.shape[0]\n",
    "            real_imgs = real_imgs.to(device)\n",
    "\n",
    "            ############################\n",
    "            # (1) entrenamos la discriminadora: max log(D(x)) + log(1 - D(G(z)))\n",
    "            \n",
    "            # ponemos en cero los gradientes de la discriminadora\n",
    "            dis.zero_grad()\n",
    "            \n",
    "            # (1.a) entrenamos con imágenes reales\n",
    "            # propagamos con imágenes reales\n",
    "            # y retropropagamos el error solo a la red discriminadora\n",
    "            dis_real_loss = forward_backward(\n",
    "                real_imgs, batch_size, real_label, dis, device)\n",
    "            \n",
    "            # (1.b) entrenamos con imágenes falsas\n",
    "            # muestreamos el espacio latente\n",
    "            z = torch.randn(batch_size, z_size, 1, 1, device=device)\n",
    "            # generamos imágenes falsas (propagamos)\n",
    "            fake_imgs = gen(z)\n",
    "            # desconectamos el tensor de la gráfica de cómputo\n",
    "            fake_imgs_detached = fake_imgs.detach()\n",
    "            # propagamos con imágenes falsas\n",
    "            # y retropropagamos el error solo a la red discriminadora\n",
    "            dis_fake_loss = forward_backward(\n",
    "                fake_imgs_detached, batch_size, fake_label, dis, device)\n",
    "            \n",
    "            # (1.c) actualizamos los parámetros de la discriminadora\n",
    "            dis_opt.step()\n",
    "\n",
    "            # pérdida global de la discriminadora\n",
    "            dis_loss = dis_real_loss + dis_fake_loss\n",
    "\n",
    "            ############################\n",
    "            # (2) entrenamos la generadora: max log(D(G(z)))\n",
    "            # ponemos en cero los gradientes de la generadora\n",
    "            gen.zero_grad()\n",
    "            # propagamos con imágenes falsas\n",
    "            # y retropropagamos el error hasta la red generadora\n",
    "            gen_loss = forward_backward(\n",
    "                fake_imgs, batch_size, real_label, dis, device)\n",
    "            # actualizamos los parámetros de la generadora\n",
    "            gen_opt.step()\n",
    "\n",
    "            # guardamos pérdidas\n",
    "            gen_loss *= 100\n",
    "            dis_loss *= 100            \n",
    "            # pérdidas por época\n",
    "            epoch_gen_losses.append(gen_loss)\n",
    "            epoch_dis_losses.append(dis_loss)\n",
    "            # historial de pérdidas\n",
    "            gen_losses.append(gen_loss)\n",
    "            dis_losses.append(dis_loss)\n",
    "            \n",
    "        if epoch % fake_imgs_save_freq == 0:\n",
    "            fake_imgs_hist.append([epoch, fake_imgs_detached.cpu()])\n",
    "\n",
    "        print(f'[{epoch}/{epochs}] '\n",
    "              f'gen_loss={np.mean(epoch_gen_losses):7.3f} '\n",
    "              f'dis_loss={np.mean(epoch_dis_losses):7.3f}')\n",
    "\n",
    "    return gen_losses, dis_losses, fake_imgs_hist\n",
    "\n",
    "set_seed()\n",
    "gen = Generator()\n",
    "dis = Discriminator()\n",
    "gen_losses, dis_losses, fake_imgs_hist = train(dl, gen, dis, epochs=25, fake_imgs_save_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pérdidas durante entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Pérdidas de la generadora y la discriminadora durante el entrenamiento')\n",
    "plt.plot(gen_losses, label='gen')\n",
    "plt.plot(dis_losses, label='dis')\n",
    "plt.xlabel('pasos')\n",
    "plt.ylabel('pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Imágenes generadas durante entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, fake_imgs in fake_imgs_hist:\n",
    "    rows = fake_imgs.shape[0] // COLS\n",
    "    print(f'Generated images at epoch {epoch}')\n",
    "    display_batch(fake_imgs, rows, COLS, figsize=(12, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Imágenes finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gen.cpu().eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(ROWS * COLS, 100, 1, 1)\n",
    "    fake_imgs = gen(z)\n",
    "display_batch(fake_imgs, ROWS, COLS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
